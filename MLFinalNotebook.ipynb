{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5rWnUY1JjTX"
      },
      "source": [
        "<h3>\n",
        "<b>Final Project: Paraphrase Identification by Multi-layer Perceptron</b>\n",
        "</h3>\n",
        "<blockquote>\n",
        "  <h5>Stephen Hullender<br/>Foundations in Machine Learning - CIS 4526<br/>Fall 2022</h5>\n",
        "</blockquote>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVJoJA_V5Odg"
      },
      "source": [
        "<h4>Imports</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6LhS1ARIkmf"
      },
      "outputs": [],
      "source": [
        "# basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sklearn\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report \n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# scipy\n",
        "from scipy import spatial\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.translate import bleu_score, meteor_score, nist_score\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Activation \n",
        "from keras.metrics import BinaryAccuracy\n",
        "\n",
        "# more NLP\n",
        "try:\n",
        "  from jiwer import compute_measures\n",
        "except:\n",
        "  !sudo pip3 install jiwer\n",
        "  from jiwer import compute_measures\n",
        "\n",
        "# others\n",
        "import calendar\n",
        "import sys\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "\n",
        "# configurations\n",
        "pd.set_option('display.max_rows', sys.maxsize)\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHp6Z-ms5UA_"
      },
      "source": [
        "<h4>Loading Text Files</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmlv487eKyOI"
      },
      "outputs": [],
      "source": [
        "# fetch from Google Drive\n",
        "SRC = \"gdrive/My Drive/MLFinal\"\n",
        "SRC_TRN = f'{SRC}/train_with_label.txt'\n",
        "SRC_DEV = f'{SRC}/dev_with_label.txt'\n",
        "SRC_TST = f'{SRC}/test_without_label.txt'\n",
        "LL = ['instance_id', 'sentence_1', 'sentence_2', 'gold_label']\n",
        "\n",
        "def load_files():\n",
        "  global train, dev, test\n",
        "  train = pd.read_csv(SRC_TRN, delimiter='[\\t]+', names=LL, on_bad_lines='skip', encoding='utf-8')\n",
        "  dev = pd.read_csv(SRC_DEV, delimiter='[\\t]+', names=LL, on_bad_lines='skip', encoding='utf-8')\n",
        "  test = pd.read_csv(SRC_TST, delimiter='[\\t]+', names=LL, on_bad_lines='skip', encoding='utf-8')\n",
        "\n",
        "from google.colab import files, drive\n",
        "try:\n",
        "  load_files()\n",
        "except:\n",
        "  drive.mount('/content/gdrive'); load_files()\n",
        "\n",
        "# test data: 7801 instances (estimated 2496 positive, 5305 negative)\n",
        "# dev data: 4000 instances (1K positive, 3K negative)\n",
        "# test data: 4000 instances (1K positive, 3K negative)\n",
        "\n",
        "# after on_bad_lines='skip'\n",
        "# train: 7578 (97.14%) || dev: 3809 (95.23%) || test: 3884 (97.10%)\n",
        "\n",
        "# after adding delimiter from '\\t' to '[\\t]+'\n",
        "# train: 7801 (100%) || dev: 4000 (100%) || test: 4000 (100%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvqfidN25ZFt"
      },
      "source": [
        "<h4>Data Preprocessing</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIufrS3h5e-r"
      },
      "source": [
        "<h6>Contractions</h6>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfrGCtTzi045"
      },
      "outputs": [],
      "source": [
        "# for processing words, distinguish contractions and make them separate words...\n",
        "\n",
        "contractions = { \n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"I'd\": \"I would\",\n",
        "  \"I'd've\": \"I would have\",\n",
        "  \"I'll\": \"I will\",\n",
        "  \"I'll've\": \"I will have\",\n",
        "  \"I'm\": \"I am\",\n",
        "  \"I've\": \"I have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it would\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"that'd\": \"that had\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there would\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"to've\": \"to have\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we would\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\",\n",
        "  \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you would\",\n",
        "  \"you'd've\": \"you would have\",\n",
        "  \"you'll\": \"you will\",\n",
        "  \"you'll've\": \"you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qotvIguF5hm5"
      },
      "source": [
        "<h6>Regular Expressions, Stopwords</h6>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkIFigyfrO0l"
      },
      "outputs": [],
      "source": [
        "def regex(s: str):\n",
        "  s = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE)\n",
        "  s = re.sub(r'\\<a href', ' ', s)\n",
        "  s = re.sub(r'&amp;', '', s) \n",
        "  s = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', s)\n",
        "  s = re.sub(r'<br />', ' ', s)\n",
        "  s = re.sub(r'\\'', ' ', s)\n",
        "  return s;\n",
        "\n",
        "def stops(s: str):\n",
        "  s = word_tokenize(s)\n",
        "  stops = set(stopwords.words('english'))\n",
        "  words = []\n",
        "  for word in s:\n",
        "    if not word in stops:\n",
        "      words.append(word)\n",
        "  return \" \".join(words)\n",
        "\n",
        "def clean_text(sentence: str):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = sentence.split()\n",
        "  text = []\n",
        "  for word in sentence:\n",
        "    text.append(contractions[word] if word in contractions else word)\n",
        "  sentence = \" \".join(text)\n",
        "  sentence = regex(sentence)\n",
        "  sentence = stops(sentence)\n",
        "  sentence = WordPunctTokenizer().tokenize(sentence)\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1UEwlLq5mbF"
      },
      "source": [
        "<h6>Lemmatization</h6>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-5wX4bFrOcn"
      },
      "outputs": [],
      "source": [
        "# use the functions above to parse all words into separate elements in a list\n",
        "# and take out punctuation and stopwords\n",
        "\n",
        "# lemmatize text, last step in cleaning words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for table in [train, dev, test]:\n",
        "  table['new_sentence_1'] = list(map(clean_text, table['sentence_1']))\n",
        "  table['new_sentence_2'] = list(map(clean_text, table['sentence_2']))\n",
        "\n",
        "  # lemmatize first column\n",
        "  table['new_sentence_1'] = list(map(\n",
        "    lambda word: list(map(lemmatizer.lemmatize, word)),\n",
        "    table['new_sentence_1']\n",
        "  ))\n",
        "\n",
        "  # lemmatize second column\n",
        "  table['new_sentence_2'] = list(map(\n",
        "    lambda word: list(map(lemmatizer.lemmatize, word)),\n",
        "    table['new_sentence_2']\n",
        "  ))\n",
        "\n",
        "  # & drop after tokenizing\n",
        "  table.drop(['sentence_1', 'sentence_2'], axis=1, inplace=True)\n",
        "\n",
        "test.drop('gold_label', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unO7s1BQocUb"
      },
      "outputs": [],
      "source": [
        "# for training and dev data, separate labels from everything else...\n",
        "gold_train = train['gold_label'].tolist()\n",
        "gold_dev = dev['gold_label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oXjDI1c5pcf"
      },
      "source": [
        "<h4>TFIDF Vectorization</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju537hkxuwwe"
      },
      "outputs": [],
      "source": [
        "# TFIDF\n",
        "# prepare data\n",
        "n1 = train['new_sentence_1'] ; n2 = train['new_sentence_2']\n",
        "nd1 = dev['new_sentence_1'] ; nd2 = dev['new_sentence_2']\n",
        "nx1 = test['new_sentence_1'] ; nx2 = test['new_sentence_2']\n",
        "\n",
        "SP = \" \" # important to keep it spaced\n",
        "\n",
        "# vectorize\n",
        "tfidf_train_1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_train_1 = tfidf_train_1.fit_transform(n1).toarray()\n",
        "\n",
        "tfidf_train_2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_train_2 = tfidf_train_2.fit_transform(n2).toarray()\n",
        "\n",
        "tfidf_dev_1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_dev_1 = tfidf_dev_1.fit_transform(nd1).toarray()\n",
        "\n",
        "tfidf_dev_2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_dev_2 = tfidf_dev_2.fit_transform(nd2).toarray()\n",
        "\n",
        "tfidf_test_1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_test_1 = tfidf_test_1.fit_transform(nx1).toarray()\n",
        "\n",
        "tfidf_test_2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=SP.join, stop_words='english', lowercase=False)\n",
        "arr_test_2 = tfidf_test_2.fit_transform(nx2).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuO_lzqK5wTD"
      },
      "source": [
        "<h4>Include Missing Features for Training, Dev, and Testing Datasets</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU9_sAkayuAu"
      },
      "outputs": [],
      "source": [
        "# add x number of arrays of same length to accomodate for missing words\n",
        "# get words that are available in one set but not another\n",
        "train_1_not_2 = list(set(tfidf_train_1.get_feature_names_out()).difference(tfidf_train_2.get_feature_names_out()))\n",
        "train_2_not_1 = list(set(tfidf_train_2.get_feature_names_out()).difference(tfidf_train_1.get_feature_names_out()))\n",
        "dev_1_not_2 = list(set(tfidf_dev_1.get_feature_names_out()).difference(tfidf_dev_2.get_feature_names_out()))\n",
        "dev_2_not_1 = list(set(tfidf_dev_2.get_feature_names_out()).difference(tfidf_dev_1.get_feature_names_out()))\n",
        "test_1_not_2 = list(set(tfidf_test_1.get_feature_names_out()).difference(tfidf_test_2.get_feature_names_out()))\n",
        "test_2_not_1 = list(set(tfidf_test_2.get_feature_names_out()).difference(tfidf_test_1.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79BG9IpKyoTO"
      },
      "outputs": [],
      "source": [
        "# change feature names to fit all words\n",
        "def change_features(arr, exclusion):\n",
        "  ret = []\n",
        "  for i in range(len(arr)):\n",
        "    temp = list(arr[i])\n",
        "    temp.extend([0] * len(exclusion))\n",
        "    ret.append(temp)\n",
        "  return np.array(ret)\n",
        "\n",
        "# use this later to replace new_sentence_X with encoding\n",
        "arr_train_1 = change_features(arr_train_1, train_2_not_1)\n",
        "arr_train_2 = change_features(arr_train_2, train_1_not_2)\n",
        "arr_dev_1 = change_features(arr_dev_1, dev_2_not_1)\n",
        "arr_dev_2 = change_features(arr_dev_2, dev_1_not_2)\n",
        "arr_test_1 = change_features(arr_test_1, test_2_not_1)\n",
        "arr_test_2 = change_features(arr_test_2, test_1_not_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjKC9ZX-vlBU"
      },
      "outputs": [],
      "source": [
        "# conjoin features \n",
        "features_train = list(tfidf_train_1.get_feature_names_out())\n",
        "features_train.extend(train_2_not_1)\n",
        "\n",
        "features_dev = list(tfidf_dev_1.get_feature_names_out())\n",
        "features_dev.extend(dev_2_not_1)\n",
        "\n",
        "features_test = list(tfidf_test_1.get_feature_names_out())\n",
        "features_test.extend(test_2_not_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vKvOxKuoF1j"
      },
      "source": [
        "<h4>FEATURE: Overlapping Words</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWk4m1-foE_a"
      },
      "outputs": [],
      "source": [
        "def get_overlapping(arr1, arr2):\n",
        "  assert len(arr1) == len(arr2)\n",
        "  over = []\n",
        "  for i in range(len(arr1)):\n",
        "    set_doc1 = set(arr1[i]); set_doc2 = set(arr2[i])\n",
        "    overlaps = set_doc1 & set_doc2\n",
        "    score = abs(\n",
        "        (len(overlaps) / len(list(set_doc1))) - (len(overlaps) / len(list(set_doc2)))\n",
        "    )\n",
        "    over.append(score)\n",
        "  return over\n",
        "\n",
        "overlap_train = get_overlapping(n1, n2)\n",
        "overlap_dev = get_overlapping(nd1, nd2)\n",
        "overlap_test = get_overlapping(nx1, nx2)\n",
        "\n",
        "print(overlap_train, '\\n', overlap_dev, '\\n', overlap_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2uWbFNqf3lY"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: Jaccard Similarity\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC6aXW8nf6Q8"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# FEATURE: Jaccard\n",
        "#\n",
        "def jaccard(arr1, arr2):\n",
        "  assert len(arr1) == len(arr2)\n",
        "  ret = []\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    s1 = set(doc1); s2 = set(doc2)\n",
        "    ret.append(\n",
        "        float(len(s1 & s2) / len(s1.union(s2)))\n",
        "    )\n",
        "  return ret\n",
        "\n",
        "jaccard_similarity_train = jaccard(n1, n2)\n",
        "jaccard_similarity_dev = jaccard(nd1, nd2)\n",
        "jaccard_similarity_test = jaccard(nx1, nx2)\n",
        "\n",
        "print(jaccard_similarity_train, '\\n', jaccard_similarity_dev, '\\n', jaccard_similarity_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-k54W6S2XHw"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: Cosine Similarity (Average, Count, Average on Nonzero Occurrences)\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x55_PbWtsdGL"
      },
      "outputs": [],
      "source": [
        "# each cosine_sim_XX returns a cosine similarity score based on comparing the two sentences\n",
        "# the reason for 1 - spatial.distance.cosine is to only calculate similarity (otherwise, you'll get the difference)\n",
        "def get_cosine(n1, n2):\n",
        "  assert len(n1) == len(n2)\n",
        "  return [1 - spatial.distance.cosine(n1[i], n2[i]) for i in range(len(n1))]\n",
        "\n",
        "cosine_sim_train = get_cosine(arr_train_1, arr_train_2)\n",
        "cosine_sim_dev = get_cosine(arr_dev_1, arr_dev_2)\n",
        "cosine_sim_test = get_cosine(arr_test_1, arr_test_2)\n",
        "\n",
        "print(len(arr_train_1)) # total number of rows (documents)\n",
        "print(len(arr_train_1[0])) # for each row, print all possible cosine distances for each available word (feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGkF-Jev7coI"
      },
      "outputs": [],
      "source": [
        "# average cosine score for all \n",
        "def get_avg_cosine(arr):\n",
        "  return np.average(arr)\n",
        "\n",
        "# ::::: EXTRA: average cosine similarity per document\n",
        "avg_cosine_train = get_avg_cosine(cosine_sim_train)\n",
        "avg_cosine_dev = get_avg_cosine(cosine_sim_dev)\n",
        "avg_cosine_test = get_avg_cosine(cosine_sim_test)\n",
        "\n",
        "print(\"Average cosine similarity scores:\")\n",
        "print(avg_cosine_train, avg_cosine_dev, avg_cosine_test)\n",
        "\n",
        "# out of the scores given for each data, how many are zeroes\n",
        "def get_no_match(arr):\n",
        "  ret = arr.count(0.00)\n",
        "  return ret / len(arr)\n",
        "\n",
        "# average cosine for only scores that are non-zero\n",
        "def get_avg_cosine_nonzero(arr):\n",
        "  ret = []\n",
        "  for a in arr:\n",
        "    if a > 0.00:\n",
        "      ret.append(a)\n",
        "  return sum(ret) / len(ret)\n",
        "\n",
        "# ::::: EXTRA: count how many matches in each document return no similarity (cosine)\n",
        "no_match_cosine_train = get_no_match(cosine_sim_train)\n",
        "no_match_cosine_dev = get_no_match(cosine_sim_dev)\n",
        "no_match_cosine_test = get_no_match(cosine_sim_test)\n",
        "\n",
        "print(\"How many are no matches:\")\n",
        "print(no_match_cosine_train, no_match_cosine_dev, no_match_cosine_test)\n",
        "\n",
        "# ::::: EXTRA: count all non-zero averages for cosine similarity\n",
        "nonzero_avg_train = get_avg_cosine_nonzero(cosine_sim_train)\n",
        "nonzero_avg_dev = get_avg_cosine_nonzero(cosine_sim_dev)\n",
        "nonzero_avg_test = get_avg_cosine_nonzero(cosine_sim_test)\n",
        "\n",
        "print(\"Nonzero averages:\")\n",
        "print(nonzero_avg_train, nonzero_avg_dev, nonzero_avg_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv-CXtGB2cBZ"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: BLEU Scores\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOfVhHf4rLfT"
      },
      "outputs": [],
      "source": [
        "# calculate BLEU scores\n",
        "# each array in the returned list contains the results of each document, differing by weight\n",
        "def bleu(arr1, arr2):\n",
        "  bleu_features = [\"BLEU_1\", \"BLEU_2\", \"BLEU_3\", \"BLEU_4\"]\n",
        "  bleus = [[], [], [], []]\n",
        "  assert len(arr1) == len(arr2)\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    for x in range(len(bleu_features)):\n",
        "      bleus[x].append(\n",
        "          round(bleu_score.sentence_bleu([doc1], doc2, weights=([1/(x+1)] * (x+1))), 12)\n",
        "      )\n",
        "  return bleus \n",
        "\n",
        "#\n",
        "# ::::: FEATURE: BLEU scores (4-set)\n",
        "#\n",
        "blue_train = bleu(n1, n2)\n",
        "# e.g. [[weights=1], [weights=(1/2)*2], [weights=(1/3)*3], [weights=(1/4)*4]]\n",
        "blue_dev = bleu(nd1, nd2)\n",
        "blue_test = bleu(nx1, nx2)\n",
        "\n",
        "print(blue_train, '\\n', blue_dev, '\\n', blue_test)\n",
        "print(len(blue_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHOr6Cwo2eL0"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: METEOR Scores\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tYMV7_bxB53"
      },
      "outputs": [],
      "source": [
        "# calculate METEOR scores\n",
        "#\n",
        "def meteor(arr1, arr2):\n",
        "  assert len(arr1) == len(arr2);\n",
        "  m = []\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    m.append(\n",
        "        round(meteor_score.single_meteor_score(doc1, doc2), 6)\n",
        "    )\n",
        "  return m\n",
        "\n",
        "#\n",
        "# ::::: FEATURE: METEOR scores\n",
        "#\n",
        "meteor_train = meteor(n1, n2)\n",
        "meteor_dev = meteor(nd1, nd2)\n",
        "meteor_test = meteor(nx1, nx2)\n",
        "\n",
        "print(meteor_train, '\\n', meteor_dev, '\\n', meteor_test)\n",
        "print(len(meteor_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uUqlah02mAV"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: NIST Scores\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGpA_LwX1qfu"
      },
      "outputs": [],
      "source": [
        "# calculate NIST scores\n",
        "def nist(arr1, arr2):\n",
        "  assert len(arr1) == len(arr2)\n",
        "  n = [[], [], []]\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    for x in range(3):\n",
        "      n[x].append(\n",
        "        nist_score.sentence_nist([doc1], doc2, n=(x+1))\n",
        "      )\n",
        "    # n=3 is the highest n-gram order that works without division-by-zero error.\n",
        "  return n\n",
        "\n",
        "#\n",
        "# ::::: FEATURE: NIST scores (3-set)\n",
        "#\n",
        "nist_train = nist(n1, n2)\n",
        "# e.g. [[n=1], [n=2], [n=3]]\n",
        "nist_dev = nist(nd1, nd2)\n",
        "nist_test = nist(nx1, nx2)\n",
        "\n",
        "print(nist_train, '\\n', nist_dev, '\\n', nist_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "narOADmdswPu"
      },
      "source": [
        "<h4>\n",
        "  FEATURES: Bigram & Trigram Features\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un6n3xQyswnS"
      },
      "outputs": [],
      "source": [
        "def get_gram(n, arr1, arr2):\n",
        "  assert len(arr1) == len(arr2)\n",
        "  ret_union = []\n",
        "  ret_intersection = []\n",
        "  ret_grams1 = []\n",
        "  ret_grams2 = []\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    g1 = [doc1[j:j+n] for j in range(len(doc1))]\n",
        "    g2 = [doc2[j:j+n] for j in range(len(doc2))]\n",
        "    # total number of n-grams available for both documents\n",
        "    ret_union.append(len(g1) + len(g2))\n",
        "    # number of n-grams that match between the two documents\n",
        "    ret_intersection.append(len([x for x in g1 if x in g2]))\n",
        "    # and for g1 and g2, the number of n-grams from each individual document\n",
        "    ret_grams1.append(len(g1))\n",
        "    ret_grams2.append(len(g2))\n",
        "  return ret_union, ret_intersection, ret_grams1, ret_grams2\n",
        "\n",
        "# for n=2\n",
        "bigram_union_train, bigram_inter_train, bigram_1_train, bigram_2_train = get_gram(2, n1, n2)\n",
        "bigram_union_dev, bigram_inter_dev, bigram_1_dev, bigram_2_dev = get_gram(2, nd1, nd2)\n",
        "bigram_union_test, bigram_inter_test, bigram_1_test, bigram_2_test = get_gram(2, nx1, nx2)\n",
        "\n",
        "print(bigram_union_train, '\\n', bigram_inter_train, '\\n', bigram_1_train, '\\n', bigram_2_train)\n",
        "\n",
        "# for n=3\n",
        "trigram_union_train, trigram_inter_train, trigram_1_train, trigram_2_train = get_gram(3, n1, n2)\n",
        "trigram_union_dev, trigram_inter_dev, trigram_1_dev, trigram_2_dev = get_gram(3, nd1, nd2)\n",
        "trigram_union_test, trigram_inter_test, trigram_1_test, trigram_2_test = get_gram(3, nx1, nx2)\n",
        "\n",
        "print(trigram_union_train, '\\n', trigram_inter_train, '\\n', trigram_1_train, '\\n', trigram_2_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA3l9JDr81oF"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: Levenshtein distance\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKgBiczX_hJq"
      },
      "outputs": [],
      "source": [
        "from functools import lru_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ida1L7Fc81Ve"
      },
      "outputs": [],
      "source": [
        "def lev_distance(arr1, arr2):\n",
        "\n",
        "  @lru_cache(None)\n",
        "  def min_distance(s1, s2):\n",
        "    if s1 == len(arr1) or s2 == len(arr2):\n",
        "      return len(arr1) - s1 + len(arr2) - s2\n",
        "    if arr1[s1] == arr2[s2]:\n",
        "      return min_distance(s1+1, s2+1)\n",
        "    return 1 + min(\n",
        "      min_distance(s1, s2 + 1),\n",
        "      min_distance(s1 + 1, s2),\n",
        "      min_distance(s1 + 1, s2 + 1)\n",
        "    )\n",
        "  return min_distance(0, 0)\n",
        "\n",
        "def calculate_lev(arr1, arr2):\n",
        "  assert len(arr1) == len(arr2)\n",
        "  ret = []\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    ret.append(lev_distance(doc1, doc2))\n",
        "  return ret\n",
        "\n",
        "#\n",
        "# ::::: FEATURES: levenshtein distance \n",
        "#\n",
        "lev_train = calculate_lev(n1, n2)\n",
        "lev_dev = calculate_lev(nd1, nd2)\n",
        "lev_test = calculate_lev(nx1, nx2)\n",
        "\n",
        "print(lev_train, '\\n', lev_dev, '\\n', lev_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrLyvUkvrQ98"
      },
      "source": [
        "<h4>\n",
        "  FEATURE: Euclidean distance\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMxFeFU4iL5N"
      },
      "outputs": [],
      "source": [
        "def euc(arr1, arr2):\n",
        "  ret = []\n",
        "  assert len(arr1) == len(arr2)\n",
        "  for i in range(len(arr1)):\n",
        "    x = euclidean_distances([arr1[i]], [arr2[i]])\n",
        "    ret.append(x[0].tolist()[0])\n",
        "  #for i in range(len(arr1)):\n",
        "  #  doc1 = np.array(arr1[i]); doc2 = np.array(arr2[i])\n",
        "  #  e = np.linalg.norm(doc1 - doc2)\n",
        "  #  ret.append(e)\n",
        "  return ret\n",
        "\n",
        "#\n",
        "# ::::: FEATURES: euclidean\n",
        "#\n",
        "euc_train = euc(arr_train_1, arr_train_2)\n",
        "euc_dev = euc(arr_dev_1, arr_dev_2)\n",
        "euc_test = euc(arr_test_1, arr_test_2)\n",
        "\n",
        "print(euc_train, '\\n', euc_dev, '\\n', euc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU_BuAj56M-A"
      },
      "source": [
        "<h4>\n",
        "  FINAL FEATURE: Word Error Rate\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43fv9iDF6MZ-"
      },
      "outputs": [],
      "source": [
        "# using wer (from jiwer)\n",
        "def conjoin_for_word_error(doc):\n",
        "  return \" \".join(doc)\n",
        "\n",
        "def word_error(arr1, arr2):\n",
        "  ret = []\n",
        "  assert len(arr1) == len(arr2)\n",
        "  for i in range(len(arr1)):\n",
        "    doc1 = arr1[i]; doc2 = arr2[i]\n",
        "    doc1 = conjoin_for_word_error(doc1)\n",
        "    doc2 = conjoin_for_word_error(doc2)\n",
        "    errors = compute_measures(doc1, doc2)\n",
        "    ret.append(errors)\n",
        "  print(ret)\n",
        "  return ret\n",
        "\n",
        "def get_wer(arr1, arr2):\n",
        "  values = word_error(arr1, arr2)\n",
        "  wer = []; wil = []\n",
        "  subs = []; dels = []; inserts = []\n",
        "  for v in values:\n",
        "    wer.append(v['wer'])\n",
        "    wil.append(v['wil'])\n",
        "    subs.append(v['substitutions'])\n",
        "    dels.append(v['deletions'])\n",
        "    inserts.append(v['insertions'])\n",
        "  ret = [wer, wil, subs, dels, inserts]\n",
        "  return ret\n",
        "\n",
        "wer_train = get_wer(n1, n2)\n",
        "wer_dev = get_wer(nd1, nd2)\n",
        "wer_test = get_wer(nx1, nx2)\n",
        "# prints out: wer, mer, wil, wip, hits, substitutions, deletions, insertions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRwxA20dwJz"
      },
      "source": [
        "<h4>\n",
        "  Putting Everything Together\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_instance_ids = test['instance_id'].tolist()"
      ],
      "metadata": {
        "id": "6cjy5Xn6VKaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn1UwlNTpKQ-"
      },
      "outputs": [],
      "source": [
        "# save results\n",
        "def print_results(a, p, keras=0):\n",
        "  lbl = [\"accuracy\", \"precision\", \"recall\", \"F1\"]\n",
        "  AVG='weighted'\n",
        "\n",
        "  acc = accuracy_score(a, p)\n",
        "  pre = precision_score(a, p, average=AVG)\n",
        "  rec = recall_score(a, p, average=AVG)\n",
        "  f1 = f1_score(a, p, average=AVG)\n",
        "\n",
        "  data = [acc, pre, rec, f1]\n",
        "  df = pd.DataFrame(data, index=lbl)\n",
        "\n",
        "  ts = str(calendar.timegm(time.gmtime()))\n",
        "  df['timestamp'] = ts\n",
        "  df['model'] = \"keras\" if keras > 0 else \"sklearn\"\n",
        "\n",
        "  filename = f'{SRC}/mlfinal_list_of_results.txt'\n",
        "\n",
        "  with open(filename, 'a') as f:\n",
        "    dfAsString = df.to_string(header=True, index=True)\n",
        "    f.write(dfAsString + \"\\n\")\n",
        "    f.close()\n",
        "\n",
        "  print('ACCURACY: ', acc)\n",
        "  print('PRECISION: ', pre)\n",
        "  print('RECALL: ', rec)\n",
        "  print(\"F1-SCORE: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uImS-jVLa7H0"
      },
      "outputs": [],
      "source": [
        "# ::: All features :::\n",
        "# overlapping words\n",
        "# jaccard similarity\n",
        "# cosine similarity\n",
        "# BLEU (4)\n",
        "# METEOR\n",
        "# NIST (3)\n",
        "# bigram\n",
        "# trigram\n",
        "# Levenshtein\n",
        "# Euclidean\n",
        "# & word error rate features { wer, wil, substitutions, deletions, insertions } (5)\n",
        "\n",
        "data_train = train\n",
        "\n",
        "data_train.drop('new_sentence_1', axis=1, inplace=True)\n",
        "data_train.drop('new_sentence_2', axis=1, inplace=True)\n",
        "data_train.drop('instance_id', axis=1, inplace=True)\n",
        "\n",
        "data_train[\"overlapping_words\"] = overlap_train\n",
        "data_train[\"jaccard_similarity\"] = jaccard_similarity_train\n",
        "data_train[\"cosine_similarity\"] = cosine_sim_train\n",
        "data_train[\"bleu_1\"] = blue_train[0]\n",
        "data_train[\"bleu_2\"] = blue_train[1]\n",
        "data_train[\"bleu_3\"] = blue_train[2]\n",
        "data_train[\"bleu_4\"] = blue_train[3]\n",
        "data_train[\"meteor\"] = meteor_train\n",
        "data_train[\"nist_1\"] = nist_train[0]\n",
        "data_train[\"nist_2\"] = nist_train[1]\n",
        "data_train[\"nist_3\"] = nist_train[2]\n",
        "data_train[\"bigram_union\"] = bigram_union_train\n",
        "data_train[\"bigram_intersection\"] = bigram_inter_train\n",
        "data_train[\"bigram_1\"] = bigram_1_train \n",
        "data_train[\"bigram_2\"] = bigram_2_train \n",
        "data_train[\"trigram_union\"] = trigram_union_train\n",
        "data_train[\"trigram_intersection\"] = trigram_inter_train \n",
        "data_train[\"trigram_1\"] = trigram_1_train \n",
        "data_train[\"trigram_2\"] = trigram_2_train \n",
        "data_train[\"levenshtein\"] = lev_train\n",
        "data_train[\"euclidean\"] = euc_train\n",
        "data_train['word_error_rate'] = wer_train[0]\n",
        "data_train['word_info_lost'] = wer_train[1]\n",
        "data_train['wer_substitutions'] = wer_train[2]\n",
        "data_train['wer_deletions'] = wer_train[3]\n",
        "data_train['wer_insertions'] = wer_train[4]\n",
        "\n",
        "# show all\n",
        "data_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cjtvL2dsnVq"
      },
      "outputs": [],
      "source": [
        "data_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I7zZID-2Tnj"
      },
      "outputs": [],
      "source": [
        "data_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id6lnKRT2Vtt"
      },
      "outputs": [],
      "source": [
        "data_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62PZ0XRRLR9f"
      },
      "outputs": [],
      "source": [
        "# same thing for both dev and test sets\n",
        "\n",
        "# DEV\n",
        "data_dev = dev\n",
        "\n",
        "data_dev.drop('new_sentence_1', axis=1, inplace=True)\n",
        "data_dev.drop('new_sentence_2', axis=1, inplace=True)\n",
        "data_dev.drop('instance_id', axis=1, inplace=True)\n",
        "\n",
        "data_dev[\"overlapping_words\"] = overlap_dev\n",
        "data_dev[\"jaccard_similarity\"] = jaccard_similarity_dev\n",
        "data_dev[\"cosine_similarity\"] = cosine_sim_dev\n",
        "data_dev[\"bleu_1\"] = blue_dev[0]\n",
        "data_dev[\"bleu_2\"] = blue_dev[1]\n",
        "data_dev[\"bleu_3\"] = blue_dev[2]\n",
        "data_dev[\"bleu_4\"] = blue_dev[3]\n",
        "data_dev[\"meteor\"] = meteor_dev\n",
        "data_dev[\"nist_1\"] = nist_dev[0]\n",
        "data_dev[\"nist_2\"] = nist_dev[1]\n",
        "data_dev[\"nist_3\"] = nist_dev[2]\n",
        "data_dev[\"bigram_union\"] = bigram_union_dev\n",
        "data_dev[\"bigram_intersection\"] = bigram_inter_dev\n",
        "data_dev[\"bigram_1\"] = bigram_1_dev \n",
        "data_dev[\"bigram_2\"] = bigram_2_dev \n",
        "data_dev[\"trigram_union\"] = trigram_union_dev\n",
        "data_dev[\"trigram_intersection\"] = trigram_inter_dev \n",
        "data_dev[\"trigram_1\"] = trigram_1_dev \n",
        "data_dev[\"trigram_2\"] = trigram_2_dev \n",
        "data_dev[\"levenshtein\"] = lev_dev\n",
        "data_dev[\"euclidean\"] = euc_dev\n",
        "data_dev['word_error_rate'] = wer_dev[0]\n",
        "data_dev['word_info_lost'] = wer_dev[1]\n",
        "data_dev['wer_substitutions'] = wer_dev[2]\n",
        "data_dev['wer_deletions'] = wer_dev[3]\n",
        "data_dev['wer_insertions'] = wer_dev[4]\n",
        "\n",
        "# TEST\n",
        "data_test = test\n",
        "\n",
        "data_test.drop('new_sentence_1', axis=1, inplace=True)\n",
        "data_test.drop('new_sentence_2', axis=1, inplace=True)\n",
        "data_test.drop('instance_id', axis=1, inplace=True)\n",
        "\n",
        "data_test[\"overlapping_words\"] = overlap_test\n",
        "data_test[\"jaccard_similarity\"] = jaccard_similarity_test\n",
        "data_test[\"cosine_similarity\"] = cosine_sim_test\n",
        "data_test[\"bleu_1\"] = blue_test[0]\n",
        "data_test[\"bleu_2\"] = blue_test[1]\n",
        "data_test[\"bleu_3\"] = blue_test[2]\n",
        "data_test[\"bleu_4\"] = blue_test[3]\n",
        "data_test[\"meteor\"] = meteor_test\n",
        "data_test[\"nist_1\"] = nist_test[0]\n",
        "data_test[\"nist_2\"] = nist_test[1]\n",
        "data_test[\"nist_3\"] = nist_test[2]\n",
        "data_test[\"bigram_union\"] = bigram_union_test\n",
        "data_test[\"bigram_intersection\"] = bigram_inter_test\n",
        "data_test[\"bigram_1\"] = bigram_1_test \n",
        "data_test[\"bigram_2\"] = bigram_2_test \n",
        "data_test[\"trigram_union\"] = trigram_union_test\n",
        "data_test[\"trigram_intersection\"] = trigram_inter_test \n",
        "data_test[\"trigram_1\"] = trigram_1_test \n",
        "data_test[\"trigram_2\"] = trigram_2_test \n",
        "data_test[\"levenshtein\"] = lev_test\n",
        "data_test[\"euclidean\"] = euc_test\n",
        "data_test['word_error_rate'] = wer_test[0]\n",
        "data_test['word_info_lost'] = wer_test[1]\n",
        "data_test['wer_substitutions'] = wer_test[2]\n",
        "data_test['wer_deletions'] = wer_test[3]\n",
        "data_test['wer_insertions'] = wer_test[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IssC5LA52jP4"
      },
      "outputs": [],
      "source": [
        "# test train_test_split for now\n",
        "\n",
        "# for train\n",
        "X = data_train.drop('gold_label', axis=1)\n",
        "y = data_train['gold_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# ... works better when random_state is 123\n",
        "clf = MLPClassifier(random_state=123, max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "print(cm)\n",
        "print_results(y_test, preds)\n",
        "\n",
        "# for dev\n",
        "A = data_dev.drop('gold_label', axis=1)\n",
        "b = data_dev['gold_label'] \n",
        "preds2 = clf.predict(A.values)\n",
        "cm2 = confusion_matrix(b.values, preds2)\n",
        "print(cm2)\n",
        "print_results(b.values, preds2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovgJSgpTuxMr"
      },
      "outputs": [],
      "source": [
        "# IDK THIS\n",
        "# Source: https://www.youtube.com/watch?v=8_bT0z3AFmA&ab_channel=BhavyaSriYarlagadda\n",
        "columns = data_train.columns.values\n",
        "last_index = len(columns) - 1\n",
        "\n",
        "j = data_train['gold_label']\n",
        "I = data_train.drop(['gold_label'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEUiPo--uxE_"
      },
      "outputs": [],
      "source": [
        "I_train, I_test, j_train, j_test = train_test_split(I, j, test_size=0.3, random_state=1)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(15, activation='relu', input_shape=(last_index,)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if missing values are shown (should not be an issue)\n",
        "for i in range(4000):\n",
        "  check = f'test_id_{i}'\n",
        "  if not check in final_instance_ids:\n",
        "    final_instance_ids.insert(i, check)\n",
        "    final_preds = np.insert(final_preds, i, '0')"
      ],
      "metadata": {
        "id": "D0nfgTFET462"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [3000, 1200, 500, 100]\n",
        "batch_size = [50, 25]\n",
        "amf = [[], [], [], []]\n",
        "# group by epoch\n",
        "\n",
        "M = data_dev.drop(['gold_label'], axis=1)\n",
        "n = data_dev['gold_label']"
      ],
      "metadata": {
        "id": "YLNUA-HSe3_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TIXXCsfO4BY"
      },
      "outputs": [],
      "source": [
        "for e in range(len(epochs)):\n",
        "  for b in batch_size:\n",
        "\n",
        "    hist = model.fit(I_train, j_train, batch_size=b, epochs=epochs[e], validation_split=0.2)\n",
        "    amf[e].append(hist)\n",
        "\n",
        "    predictions = model.predict(I_train)\n",
        "    predictions = [1 if y >= 0.5 else 0 for y in predictions]\n",
        "    print(len(predictions))\n",
        "    print_results(j_train, predictions, keras=1)\n",
        "\n",
        "    more_predictions = model.predict(I_test)\n",
        "    more_predictions = [1 if z >= 0.5 else 0 for z in more_predictions]\n",
        "    print(len(more_predictions))\n",
        "    print_results(j_test, more_predictions, keras=1)\n",
        "\n",
        "    dev_predictions = model.predict(M.values)\n",
        "    dev_predictions = [1 if y >= 0.5 else 0 for y in dev_predictions]\n",
        "    print(len(dev_predictions))\n",
        "    print_results(n, dev_predictions, keras=1)\n",
        "\n",
        "    final_preds = model.predict(data_test.values)  \n",
        "    final_preds = [1 if y >= 0.5 else 0 for y in final_preds]\n",
        "    ts = ts = str(calendar.timegm(time.gmtime()))\n",
        "    with open(f'{SRC}/mlfinal_final_results_{ts}.txt', 'a') as f:\n",
        "      for i in range(len(final_preds)):\n",
        "        f.write(str(final_instance_ids[i]) + '\\t' + str(final_preds[i]) + '\\n')\n",
        "      f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Results, Visualizations</h4>"
      ],
      "metadata": {
        "id": "bWoYZfc40A0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftkSMCu63Mra"
      },
      "outputs": [],
      "source": [
        "# show for epochs 3000, batchsize 50, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[0][0].history['loss'])\n",
        "plt.plot(amf[0][0].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rS3V3KX3MpV"
      },
      "outputs": [],
      "source": [
        "# show for epochs 3000, batchsize 50, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[0][0].history['accuracy'])\n",
        "plt.plot(amf[0][0].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ6m5owgMZhE"
      },
      "outputs": [],
      "source": [
        "# show for epochs 3000, batchsize 25, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[0][1].history['loss'])\n",
        "plt.plot(amf[0][1].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U3bV6--MZhK"
      },
      "outputs": [],
      "source": [
        "# show for epochs 3000, batchsize 25, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[0][1].history['accuracy'])\n",
        "plt.plot(amf[0][1].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OOsgJtoMbcL"
      },
      "outputs": [],
      "source": [
        "# show for epochs 1200, batchsize 50, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[1][0].history['loss'])\n",
        "plt.plot(amf[1][0].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF0PF_2zMbcM"
      },
      "outputs": [],
      "source": [
        "# show for epochs 1200, batchsize 50, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[1][0].history['accuracy'])\n",
        "plt.plot(amf[1][0].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buuz_qweMblX"
      },
      "outputs": [],
      "source": [
        "# show for epochs 1200, batchsize 25, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[1][1].history['loss'])\n",
        "plt.plot(amf[1][1].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfXH9ob3MblY"
      },
      "outputs": [],
      "source": [
        "# show for epochs 1200, batchsize 25, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[1][1].history['accuracy'])\n",
        "plt.plot(amf[1][1].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ase04QCMb_l"
      },
      "outputs": [],
      "source": [
        "# show for epochs 500, batchsize 50, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[2][0].history['loss'])\n",
        "plt.plot(amf[2][0].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j36qbP5pMb_m"
      },
      "outputs": [],
      "source": [
        "# show for epochs 500, batchsize 50, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[2][0].history['accuracy'])\n",
        "plt.plot(amf[2][0].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaSNFZ4tMcFp"
      },
      "outputs": [],
      "source": [
        "# show for epochs 500, batchsize 25, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[2][1].history['loss'])\n",
        "plt.plot(amf[2][1].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOe9IGJlMcFq"
      },
      "outputs": [],
      "source": [
        "# show for epochs 500, batchsize 25, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[2][1].history['accuracy'])\n",
        "plt.plot(amf[2][1].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBOAagH0McQe"
      },
      "outputs": [],
      "source": [
        "# show for epochs 100, batchsize 50, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[3][0].history['loss'])\n",
        "plt.plot(amf[3][0].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL5MzRXCMcQe"
      },
      "outputs": [],
      "source": [
        "# show for epochs 100, batchsize 50, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[3][0].history['accuracy'])\n",
        "plt.plot(amf[3][0].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTU6eNnXMcVJ"
      },
      "outputs": [],
      "source": [
        "# show for epochs 100, batchsize 25, loss\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[3][1].history['loss'])\n",
        "plt.plot(amf[3][1].history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98mjRsyNMcVK"
      },
      "outputs": [],
      "source": [
        "# show for epochs 100, batchsize 25, accuracy\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(40, 24), dpi=80)\n",
        "plt.plot(amf[3][1].history['accuracy'])\n",
        "plt.plot(amf[3][1].history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for final results\n",
        "raise Exception\n",
        "\n",
        "# change after looking\n",
        "best_results = None;\n",
        "\n",
        "with open(f'{SRC}/mlfinal_final_results.txt', 'a') as f:\n",
        "  for i in range(len(final_emergency)):\n",
        "    f.write(str(final_instance_ids[i]) + '\\t' + str(best_results[i]) + '\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "n-u2tgBb8lC-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}